# -*- coding: utf-8 -*-
"""2_Data Exploration.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fxl_5EmeyiN4rPT8pRz26qnR-IB8JbNP
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2

#!pip install streamlit
#!pip install streamlit_jupyter

# Bibliotecas inicias para set up
import sys
import streamlit as st

#verificar se estamos no colab ou não e importar coisas de acordo
if 'google.colab' in sys.modules:

    # Connect Google Colab to Drive
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)

    path = '/content/drive/MyDrive/Colab Notebooks/PMDM/Project/Datasets/'

    from streamlit_jupyter import StreamlitPatcher
    sp = StreamlitPatcher()
    sp.jupyter()  # register patcher with streamlit

else:
    path = "./Datasets/"

# Imports
import pandas as pd
import matplotlib.pyplot as plt

st.set_page_config(
    page_title="PMDM Grupo 11",
    page_icon=":sports_medal:",
    layout="wide")

st.title("PMDM Grupo 11")

st.markdown("# Data Exploration")

radio_dataset = st.radio("Select Dataset:", ("Train", "Test"), horizontal=True)

if radio_dataset == "Train":
    full_path = path + "train.csv"
else:
    full_path = path + "test.csv"

# load dataset
df = pd.read_csv(full_path)

# show head
st.markdown("### .head()")
st.write(df)

# show shape
st.markdown("### .describe()")
st.write(df.describe())

st.markdown("""
Variable > Description

`Athlete Id` > ID

`Age group` > Athlete age range 

`Athlete score` > Athlete score from previous competitions

`Cancelled enrollment` > Athlete cancelled the competition enrollment 

`Cardiovascular training` > Number of training sessions such as running, cycling, or swimming

`Competition` > Type of competition

`Disability` > Athlete with disability 

`Edition` > 
  The year of the edition competition

`Education` >  Athlete education level 

`Income` > Athlete income level

`Late enrollment` > Athlete enrolled in the competition belatedly 

`Mental preparation` > Athlete has developed strategies for handling with stress and pressure

`No coach` > Athlete does not have a coach

`Other training` > Number of training sessions using non-standard approaches

`OUTCOME` > Competition result (TARGET)

`Outdoor workout` > Training conducted outdoors in parks or forests

`Past injuries` > Athlete had sport injuries

`Physiotherapy` > Number of physiotherapy sessions

`Plyometric training` > Number of training sessions involving explosive, high-intensity movements

`Previous attempts` > Number of previous competitions attempts

`RecordID` > ID of the registration of one athlete into an edition of a given competition

`Recover` > Number of recovery sessions using stretching and massages techniques

`Region` > Athlete region

`Sand training` > Number of training sessions  involving sand drills

`Sex` > Athlete sex

`Sport-specific training` > Number of training sessions that mimic competition scenarios

`Squad training` > Number of training sessions that involve a group of athletes working together to prepare for competition

`Strength training` > Number of training sessions using weightlifting and bodyweight exercises

`Supplements` > Number of nutritional supplements taken to aid performance

`Train bf competition` > Number of pre-competition preparation sessions
""")

st.markdown("### .info()")
st.write(df.info())

st.markdown("### Tipos de dados")
st.write(df.dtypes)

st.markdown("### Contagem de missing values")
st.table(df.isna().sum())

st.markdown("### Percentagem de missing values")
st.table(round(df.isna().sum()/len(df)*100, 3).apply(lambda x: '{:.3f}%'.format(x)))

st.write(f"Total de dados: {df.shape[0]}")
st.write(f"Total de dados sem missing values: {df.dropna().shape[0]}")
st.write(f"Percentagem de linhas com missing values: {round(100*(1-df.dropna().shape[0]/df.shape[0]),2)}%")

st.markdown("### Deteção de duplicados")
st.write(f'Número de duplicados: {df.duplicated().sum()}')
st.write(f'Número de duplicados no RecordID: {df.RecordID.duplicated().sum()}')
st.write(f'Número de duplicados excluindo RecordID: {df.drop(["RecordID"], axis=1).duplicated().sum()}')
st.write(f'Número de duplicados excluindo e Athlete Id: {df.drop(["RecordID", "Athlete Id"], axis=1).duplicated().sum()}')
st.write('Não parece haver duplicados!')

